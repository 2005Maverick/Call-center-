{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12225975,"sourceType":"datasetVersion","datasetId":7702806}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install librosa==0.10.1\n!pip install pydub==0.25.1\n!pip install soundfile==0.12.1\n!pip install scikit-learn==1.3.0\n!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T09:21:14.686390Z","iopub.execute_input":"2025-06-20T09:21:14.686702Z","iopub.status.idle":"2025-06-20T09:21:43.548796Z","shell.execute_reply.started":"2025-06-20T09:21:14.686679Z","shell.execute_reply":"2025-06-20T09:21:43.548086Z"}},"outputs":[{"name":"stdout","text":"Collecting librosa==0.10.1\n  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.15.2)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.13.1)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (4.13.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa==0.10.1) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa==0.10.1) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.10.1) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.10.1) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.1) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa==0.10.1) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa==0.10.1) (2024.2.0)\nDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: librosa\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.11.0\n    Uninstalling librosa-0.11.0:\n      Successfully uninstalled librosa-0.11.0\nSuccessfully installed librosa-0.10.1\nRequirement already satisfied: pydub==0.25.1 in /usr/local/lib/python3.11/dist-packages (0.25.1)\nCollecting soundfile==0.12.1\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile==0.12.1) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile==0.12.1) (2.22)\nDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: soundfile\n  Attempting uninstall: soundfile\n    Found existing installation: soundfile 0.13.1\n    Uninstalling soundfile-0.13.1:\n      Successfully uninstalled soundfile-0.13.1\nSuccessfully installed soundfile-0.12.1\nCollecting scikit-learn==1.3.0\n  Downloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.3.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.3.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.3.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.3.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.3.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.3.0) (2024.2.0)\nDownloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.3.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.3.0\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Enhanced Audio Analysis with Advanced ML and Emotion Detection\nimport os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.signal import find_peaks, savgol_filter\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import IsolationForest, RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport umap\nfrom tqdm import tqdm\nimport warnings\nimport gc\nfrom collections import Counter\nimport joblib\n\n# Audio processing libraries\nfrom pydub import AudioSegment\nimport soundfile as sf\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\nclass AdvancedEmotionClassifier:\n    \"\"\"\n    Advanced rule-based emotion classification with fuzzy logic and confidence scoring.\n    Uses multiple feature combinations and weighted scoring for better accuracy.\n    \"\"\"\n    \n    def __init__(self):\n        self.emotion_labels = ['angry', 'happy', 'sad', 'confused', 'frustrated', 'calm', 'excited', 'neutral']\n        self.feature_weights = {\n            'pitch': 0.25,\n            'energy': 0.20,\n            'rhythm': 0.15,\n            'spectral': 0.15,\n            'silence': 0.15,\n            'voice_quality': 0.10\n        }\n        print(f\"Advanced Emotion Classifier initialized with {len(self.emotion_labels)} emotion categories\")\n    \n    def _calculate_confidence(self, scores):\n        \"\"\"Calculate confidence based on score distribution\"\"\"\n        max_score = max(scores.values())\n        second_max = sorted(scores.values())[-2] if len(scores) > 1 else 0\n        confidence = (max_score - second_max) / max_score if max_score > 0 else 0\n        return min(confidence, 1.0)\n    \n    def _fuzzy_membership(self, value, low, medium, high):\n        \"\"\"Calculate fuzzy membership for continuous values\"\"\"\n        if value <= low:\n            return 'low'\n        elif value <= medium:\n            return 'medium_low' if value < (low + medium) / 2 else 'medium'\n        elif value <= high:\n            return 'medium_high' if value < (medium + high) / 2 else 'high'\n        else:\n            return 'very_high'\n    \n    def classify_emotion(self, features):\n        \"\"\"\n        Advanced emotion classification with confidence scoring\n        \"\"\"\n        scores = {emotion: 0.0 for emotion in self.emotion_labels}\n        \n        # Extract key metrics with safe defaults\n        pitch_mean = features.get('pitch', {}).get('mean', 150)\n        pitch_std = features.get('pitch', {}).get('std', 30)\n        pitch_range = features.get('pitch', {}).get('range', 50)\n        \n        energy_rms = features.get('energy', {}).get('rms', 0.03)\n        energy_variance = features.get('energy', {}).get('variance', 0.001)\n        \n        speaking_rate = features.get('rhythm', {}).get('speaking_rate', 1.5)\n        rhythm_regularity = features.get('rhythm', {}).get('regularity', 0.5)\n        \n        silence_ratio = features.get('silence', {}).get('ratio', 0.3)\n        long_pause_count = features.get('silence', {}).get('long_pause_count', 2)\n        \n        spectral_centroid = features.get('spectral', {}).get('centroid', 1500)\n        spectral_rolloff = features.get('spectral', {}).get('rolloff', 3000)\n        \n        jitter = features.get('voice_quality', {}).get('jitter', 0.01)\n        shimmer = features.get('voice_quality', {}).get('shimmer', 0.05)\n        \n        # ANGRY: High energy, high pitch variation, fast speech, harsh spectral qualities\n        if energy_rms > 0.07 and pitch_std > 60:\n            scores['angry'] += 3.0\n        if speaking_rate > 2.2 and spectral_centroid > 1700:\n            scores['angry'] += 2.0\n        if jitter > 0.015 or shimmer > 0.08:\n            scores['angry'] += 1.5\n        if pitch_range > 100:\n            scores['angry'] += 1.0\n            \n        # FRUSTRATED: Moderate energy, irregular rhythm, medium-high pitch\n        if 0.04 < energy_rms < 0.07 and rhythm_regularity < 0.4:\n            scores['frustrated'] += 2.5\n        if 160 < pitch_mean < 200 and long_pause_count > 5:\n            scores['frustrated'] += 2.0\n        if 0.3 < silence_ratio < 0.5:\n            scores['frustrated'] += 1.0\n            \n        # HAPPY/EXCITED: High energy, high pitch, regular rhythm\n        if energy_rms > 0.06 and pitch_mean > 170:\n            if speaking_rate > 2.0 and rhythm_regularity > 0.6:\n                scores['excited'] += 3.0\n            else:\n                scores['happy'] += 2.5\n        if pitch_std > 40 and energy_variance > 0.003:\n            scores['happy'] += 1.5\n            \n        # SAD: Low energy, low pitch, slow speech\n        if energy_rms < 0.03 and pitch_mean < 140:\n            scores['sad'] += 3.0\n        if speaking_rate < 1.2 and silence_ratio > 0.4:\n            scores['sad'] += 2.0\n        if spectral_centroid < 1300:\n            scores['sad'] += 1.0\n            \n        # CONFUSED: Irregular patterns, many pauses, variable energy\n        if long_pause_count > 8 and silence_ratio > 0.45:\n            scores['confused'] += 3.0\n        if rhythm_regularity < 0.3 and energy_variance > 0.004:\n            scores['confused'] += 2.0\n        if 0.02 < energy_rms < 0.05:\n            scores['confused'] += 1.0\n            \n        # CALM: Moderate, stable patterns\n        if 0.02 < energy_rms < 0.05 and pitch_std < 40:\n            scores['calm'] += 2.5\n        if 1.2 < speaking_rate < 1.8 and rhythm_regularity > 0.5:\n            scores['calm'] += 2.0\n        if 0.2 < silence_ratio < 0.35:\n            scores['calm'] += 1.0\n            \n        # NEUTRAL: Average values across metrics\n        neutral_score = 0\n        if 130 < pitch_mean < 180: neutral_score += 1\n        if 0.03 < energy_rms < 0.06: neutral_score += 1\n        if 1.5 < speaking_rate < 2.0: neutral_score += 1\n        scores['neutral'] = neutral_score\n        \n        # Calculate confidence and return result\n        confidence = self._calculate_confidence(scores)\n        predicted_emotion = max(scores, key=scores.get) if max(scores.values()) > 0 else 'neutral'\n        \n        return {\n            'emotion': predicted_emotion,\n            'confidence': confidence,\n            'scores': scores\n        }\n\nclass MultiLevelAnomalyDetector:\n    \"\"\"\n    Multi-level anomaly detection using multiple algorithms and ensemble methods\n    \"\"\"\n    \n    def __init__(self):\n        self.detectors = {\n            'isolation_forest': IsolationForest(contamination=0.15, random_state=42),\n            'statistical': None,  # Custom statistical detector\n            'pattern_based': None  # Custom pattern-based detector\n        }\n        self.scaler = StandardScaler()\n        self.is_fitted = False\n        \n    def fit(self, X, feature_names):\n        \"\"\"Fit all anomaly detectors\"\"\"\n        X_scaled = self.scaler.fit_transform(X)\n        \n        # Fit Isolation Forest\n        self.detectors['isolation_forest'].fit(X_scaled)\n        \n        # Store statistics for statistical detector\n        self.stats = {\n            'mean': np.mean(X_scaled, axis=0),\n            'std': np.std(X_scaled, axis=0),\n            'percentiles': {\n                '5': np.percentile(X_scaled, 5, axis=0),\n                '95': np.percentile(X_scaled, 95, axis=0)\n            }\n        }\n        \n        self.feature_names = feature_names\n        self.is_fitted = True\n        \n    def detect_anomalies(self, X):\n        \"\"\"Detect anomalies using ensemble approach\"\"\"\n        if not self.is_fitted:\n            raise ValueError(\"Detectors must be fitted before detecting anomalies\")\n            \n        X_scaled = self.scaler.transform(X)\n        \n        # Isolation Forest anomalies\n        iso_anomalies = (self.detectors['isolation_forest'].predict(X_scaled) == -1).astype(int)\n        \n        # Statistical anomalies (Z-score based)\n        z_scores = np.abs((X_scaled - self.stats['mean']) / (self.stats['std'] + 1e-8))\n        stat_anomalies = (np.max(z_scores, axis=1) > 3).astype(int)\n        \n        # Percentile-based anomalies\n        perc_anomalies = np.zeros(len(X_scaled))\n        for i, row in enumerate(X_scaled):\n            outside_range = ((row < self.stats['percentiles']['5']) | \n                           (row > self.stats['percentiles']['95'])).sum()\n            perc_anomalies[i] = 1 if outside_range > len(row) * 0.3 else 0\n        \n        # Ensemble decision (majority vote)\n        ensemble_anomalies = ((iso_anomalies + stat_anomalies + perc_anomalies) >= 2).astype(int)\n        \n        return {\n            'ensemble': ensemble_anomalies,\n            'isolation_forest': iso_anomalies,\n            'statistical': stat_anomalies,\n            'percentile': perc_anomalies.astype(int)\n        }\n\nclass CallPrioritizationML:\n    \"\"\"\n    Machine Learning model for call prioritization based on multiple factors\n    \"\"\"\n    \n    def __init__(self):\n        self.models = {\n            'priority_classifier': RandomForestClassifier(n_estimators=100, random_state=42),\n            'urgency_regressor': RandomForestClassifier(n_estimators=100, random_state=42),\n            'risk_scorer': LogisticRegression(random_state=42)\n        }\n        self.scalers = {name: StandardScaler() for name in self.models.keys()}\n        self.is_fitted = False\n        \n    def _create_priority_labels(self, df):\n        \"\"\"Create priority labels based on multiple criteria\"\"\"\n        priority_scores = np.zeros(len(df))\n        \n        # Emotion-based scoring\n        emotion_weights = {\n            'angry': 5, 'frustrated': 4, 'sad': 3, 'confused': 3,\n            'excited': 2, 'happy': 1, 'calm': 0, 'neutral': 0\n        }\n        for emotion, weight in emotion_weights.items():\n            priority_scores += (df['emotion_label'] == emotion) * weight\n            \n        # Anomaly scoring\n        priority_scores += df['is_anomaly'] * 3\n        \n        # Duration scoring (very long or very short calls)\n        duration_q25, duration_q75 = df['general_duration'].quantile([0.25, 0.75])\n        priority_scores += ((df['general_duration'] < duration_q25 * 0.5) | \n                          (df['general_duration'] > duration_q75 * 1.5)) * 2\n        \n        # Energy and silence patterns\n        priority_scores += (df['energy_rms'] > df['energy_rms'].quantile(0.9)) * 2\n        priority_scores += (df['silence_long_pause_count'] > df['silence_long_pause_count'].quantile(0.8)) * 1\n        \n        # Convert to categorical labels\n        priority_labels = np.where(priority_scores >= 7, 'HIGH',\n                         np.where(priority_scores >= 4, 'MEDIUM', 'LOW'))\n        \n        return priority_labels, priority_scores\n    \n    def fit(self, df, feature_columns):\n        \"\"\"Train the prioritization models\"\"\"\n        X = df[feature_columns].fillna(0)\n        \n        # Create labels\n        priority_labels, priority_scores = self._create_priority_labels(df)\n        urgency_labels = np.where(priority_scores >= 6, 2,  # High urgency\n                         np.where(priority_scores >= 3, 1, 0))  # Medium/Low urgency\n        risk_labels = (priority_scores >= 5).astype(int)  # Binary risk classification\n        \n        # Train models\n        for model_name, model in self.models.items():\n            X_scaled = self.scalers[model_name].fit_transform(X)\n            \n            if model_name == 'priority_classifier':\n                model.fit(X_scaled, priority_labels)\n            elif model_name == 'urgency_regressor':\n                model.fit(X_scaled, urgency_labels)\n            elif model_name == 'risk_scorer':\n                model.fit(X_scaled, risk_labels)\n        \n        self.feature_columns = feature_columns\n        self.is_fitted = True\n        \n        # Print model performance\n        self._evaluate_models(X, priority_labels, urgency_labels, risk_labels)\n        \n    def _evaluate_models(self, X, priority_labels, urgency_labels, risk_labels):\n        \"\"\"Evaluate model performance using cross-validation\"\"\"\n        print(\"\\nModel Performance Evaluation:\")\n        print(\"-\" * 40)\n        \n        for model_name, model in self.models.items():\n            X_scaled = self.scalers[model_name].transform(X)\n            \n            if model_name == 'priority_classifier':\n                scores = cross_val_score(model, X_scaled, priority_labels, cv=3, scoring='accuracy')\n                print(f\"Priority Classifier Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n            elif model_name == 'urgency_regressor':\n                scores = cross_val_score(model, X_scaled, urgency_labels, cv=3, scoring='accuracy')\n                print(f\"Urgency Regressor Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n            elif model_name == 'risk_scorer':\n                scores = cross_val_score(model, X_scaled, risk_labels, cv=3, scoring='roc_auc')\n                print(f\"Risk Scorer AUC: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n    \n    def predict(self, df, feature_columns):\n        \"\"\"Predict call priorities\"\"\"\n        if not self.is_fitted:\n            raise ValueError(\"Models must be fitted before prediction\")\n            \n        X = df[feature_columns].fillna(0)\n        \n        predictions = {}\n        for model_name, model in self.models.items():\n            X_scaled = self.scalers[model_name].transform(X)\n            predictions[model_name] = model.predict(X_scaled)\n            \n            if hasattr(model, 'predict_proba'):\n                predictions[f\"{model_name}_proba\"] = model.predict_proba(X_scaled)\n        \n        return predictions\n\nclass EnhancedAudioAnalyzer:\n    def __init__(self, audio_folder_path):\n        self.audio_folder = audio_folder_path\n        self.output_folder = \"/kaggle/working/enhanced_audio_analysis\"\n        os.makedirs(self.output_folder, exist_ok=True)\n        self.processed_data = []\n        self.features_df = None\n        self.emotion_classifier = AdvancedEmotionClassifier()\n        self.anomaly_detector = MultiLevelAnomalyDetector()\n        self.ml_prioritizer = CallPrioritizationML()\n        self.sample_for_timeline = None\n        \n    def _create_short_filename(self, filename):\n        \"\"\"Create short filename for labeling\"\"\"\n        base_name = os.path.splitext(filename)[0]\n        if len(base_name) > 10:\n            parts = base_name.split('_')\n            if len(parts) > 1:\n                return f\"{parts[0][:5]}_{parts[1][:5]}\"\n            return base_name[:10]\n        return base_name\n    \n    def convert_mp3_to_wav(self, mp3_path, wav_filename, target_sr=22050):\n        \"\"\"Convert MP3 to WAV with higher sample rate for better analysis\"\"\"\n        try:\n            temp_dir = \"/kaggle/working/\"\n            wav_path = os.path.join(temp_dir, wav_filename)\n            audio = AudioSegment.from_mp3(mp3_path)\n            audio = audio.set_channels(1).set_frame_rate(target_sr)\n            audio.export(wav_path, format=\"wav\")\n            return wav_path\n        except Exception as e:\n            print(f\"Error converting {mp3_path}: {str(e)}\")\n            return None\n    \n    def extract_comprehensive_features(self, audio_path, sr=22050):\n        \"\"\"Extract comprehensive audio features including voice quality metrics\"\"\"\n        try:\n            y, sr = librosa.load(audio_path, sr=sr, res_type='kaiser_fast', dtype=np.float32)\n            duration = len(y) / sr\n            \n            # Basic features\n            features = {\n                'general': {'duration': duration, 'sample_rate': sr},\n                'energy': {},\n                'spectral': {},\n                'pitch': {},\n                'rhythm': {},\n                'silence': {},\n                'voice_quality': {},\n                'temporal': {}\n            }\n            \n            # Energy features (enhanced)\n            rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]\n            features['energy'] = {\n                'rms': np.mean(rms),\n                'rms_std': np.std(rms),\n                'variance': np.var(rms),\n                'energy_entropy': self._calculate_entropy(rms),\n                'dynamic_range': np.max(rms) - np.min(rms)\n            }\n            \n            # Spectral features (enhanced)\n            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n            zcr = librosa.feature.zero_crossing_rate(y)[0]\n            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n            \n            features['spectral'] = {\n                'centroid': np.mean(spectral_centroids),\n                'centroid_std': np.std(spectral_centroids),\n                'bandwidth': np.mean(spectral_bandwidth),\n                'rolloff': np.mean(spectral_rolloff),\n                'zcr': np.mean(zcr),\n                'mfcc_mean': np.mean(mfcc, axis=1),\n                'spectral_flatness': np.mean(librosa.feature.spectral_flatness(y=y)[0])\n            }\n            \n            # Pitch features (enhanced)\n            f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=80, fmax=400, sr=sr)\n            f0_clean = f0[~np.isnan(f0)]\n            \n            if len(f0_clean) > 0:\n                features['pitch'] = {\n                    'mean': np.mean(f0_clean),\n                    'std': np.std(f0_clean),\n                    'range': np.max(f0_clean) - np.min(f0_clean),\n                    'voiced_ratio': np.mean(voiced_flag),\n                    'pitch_slope': self._calculate_pitch_slope(f0_clean)\n                }\n            else:\n                features['pitch'] = {'mean': 150, 'std': 30, 'range': 50, 'voiced_ratio': 0.5, 'pitch_slope': 0}\n            \n            # Voice quality features\n            features['voice_quality'] = self._extract_voice_quality(y, sr, f0_clean)\n            \n            # Enhanced rhythm and silence analysis\n            silence_features, rhythm_features = self._analyze_rhythm_and_silence(y, sr, rms)\n            features['silence'].update(silence_features)\n            features['rhythm'].update(rhythm_features)\n            \n            # Temporal features\n            features['temporal'] = self._extract_temporal_features(rms, sr)\n            \n            return features, y, sr, rms\n            \n        except Exception as e:\n            print(f\"Error extracting features from {audio_path}: {str(e)}\")\n            return None, None, None, None\n    \n    def _calculate_entropy(self, signal):\n        \"\"\"Calculate entropy of signal\"\"\"\n        hist, _ = np.histogram(signal, bins=50, density=True)\n        hist = hist[hist > 0]  # Remove zero probabilities\n        return -np.sum(hist * np.log2(hist))\n    \n    def _calculate_pitch_slope(self, f0):\n        \"\"\"Calculate overall pitch trend\"\"\"\n        if len(f0) < 2:\n            return 0\n        x = np.arange(len(f0))\n        slope, _, _, _, _ = stats.linregress(x, f0)\n        return slope\n    \n    def _extract_voice_quality(self, y, sr, f0_clean):\n        \"\"\"Extract voice quality metrics like jitter and shimmer\"\"\"\n        try:\n            # Simplified jitter calculation (pitch period variability)\n            if len(f0_clean) > 2:\n                periods = 1 / (f0_clean + 1e-8)\n                jitter = np.std(np.diff(periods)) / np.mean(periods) if np.mean(periods) > 0 else 0\n            else:\n                jitter = 0.01\n            \n            # Simplified shimmer calculation (amplitude variability)\n            rms_frames = librosa.feature.rms(y=y, frame_length=1024, hop_length=256)[0]\n            if len(rms_frames) > 2:\n                shimmer = np.std(np.diff(rms_frames)) / np.mean(rms_frames) if np.mean(rms_frames) > 0 else 0\n            else:\n                shimmer = 0.05\n            \n            # Harmonic-to-noise ratio approximation\n            harmonic, percussive = librosa.effects.hpss(y)\n            hnr = np.mean(harmonic**2) / (np.mean(percussive**2) + 1e-8)\n            \n            return {\n                'jitter': min(jitter, 0.1),  # Cap extreme values\n                'shimmer': min(shimmer, 0.2),\n                'hnr': min(hnr, 100)  # Cap HNR\n            }\n        except:\n            return {'jitter': 0.01, 'shimmer': 0.05, 'hnr': 10}\n    \n    def _analyze_rhythm_and_silence(self, y, sr, rms):\n        \"\"\"Enhanced rhythm and silence analysis\"\"\"\n        # Frame-based analysis\n        frame_length = int(0.025 * sr)\n        hop_length = int(0.01 * sr)\n        \n        # Voice activity detection\n        silence_threshold = np.percentile(rms, 20)\n        voice_frames = rms > silence_threshold\n        \n        # Silence features\n        silence_ratio = 1 - np.mean(voice_frames)\n        silence_segments = self._get_segments(~voice_frames)\n        silence_durations = [(seg[1] - seg[0]) * hop_length / sr for seg in silence_segments]\n        \n        silence_features = {\n            'ratio': silence_ratio,\n            'count': len(silence_segments),\n            'avg_duration': np.mean(silence_durations) if silence_durations else 0,\n            'max_duration': np.max(silence_durations) if silence_durations else 0,\n            'long_pause_count': sum(1 for d in silence_durations if d > 2.0),\n            'total_long_pause_time': sum(d for d in silence_durations if d > 2.0)\n        }\n        \n        # Rhythm features\n        voice_segments = self._get_segments(voice_frames)\n        voice_durations = [(seg[1] - seg[0]) * hop_length / sr for seg in voice_segments]\n        \n        rhythm_features = {\n            'speaking_rate': len(voice_segments) / (len(y) / sr) if len(y) > 0 else 0,\n            'avg_utterance_length': np.mean(voice_durations) if voice_durations else 0,\n            'utterance_variability': np.std(voice_durations) if len(voice_durations) > 1 else 0,\n            'regularity': 1 / (np.std(voice_durations) + 1e-8) if len(voice_durations) > 1 else 0.5\n        }\n        \n        return silence_features, rhythm_features\n    \n    def _extract_temporal_features(self, rms, sr):\n        \"\"\"Extract temporal dynamics features\"\"\"\n        # Energy contour analysis\n        energy_smooth = savgol_filter(rms, window_length=min(21, len(rms)//2*2+1), polyorder=2)\n        \n        # Find peaks and valleys\n        peaks, _ = find_peaks(energy_smooth, height=np.percentile(energy_smooth, 60))\n        valleys, _ = find_peaks(-energy_smooth, height=-np.percentile(energy_smooth, 40))\n        \n        return {\n            'num_peaks': len(peaks),\n            'num_valleys': len(valleys),\n            'peak_prominence': np.mean(energy_smooth[peaks]) if len(peaks) > 0 else 0,\n            'energy_range': np.max(rms) - np.min(rms),\n            'energy_trend': np.polyfit(range(len(rms)), rms, 1)[0] if len(rms) > 1 else 0\n        }\n    \n    def _get_segments(self, binary_array):\n        \"\"\"Get continuous segments where binary_array is True\"\"\"\n        if len(binary_array) == 0:\n            return []\n        \n        segments = []\n        start = None\n        \n        for i, val in enumerate(binary_array):\n            if val and start is None:\n                start = i\n            elif not val and start is not None:\n                segments.append((start, i))\n                start = None\n        \n        if start is not None:\n            segments.append((start, len(binary_array)))\n        \n        return segments\n    \n    def process_all_files(self):\n        \"\"\"Process all MP3 files with enhanced feature extraction\"\"\"\n        mp3_files = [f for f in os.listdir(self.audio_folder) if f.endswith('.mp3')]\n        if not mp3_files:\n            print(\"No MP3 files found!\"); return\n            \n        print(f\"Processing {len(mp3_files)} MP3 files with enhanced analysis...\")\n        \n        for mp3_file in tqdm(mp3_files, desc=\"Processing files\"):\n            mp3_path = os.path.join(self.audio_folder, mp3_file)\n            wav_filename = mp3_file.replace('.mp3', '_temp.wav')\n            wav_path = self.convert_mp3_to_wav(mp3_path, wav_filename)\n            \n            if wav_path is None:\n                continue\n                \n            features, y, sr, rms = self.extract_comprehensive_features(wav_path)\n            if features is None:\n                if os.path.exists(wav_path): os.remove(wav_path)\n                continue\n            \n            # Advanced emotion classification\n            emotion_result = self.emotion_classifier.classify_emotion(features)\n            \n            # Flatten features for DataFrame\n            flat_features = self._flatten_features(features)\n            \n            # Combine all data\n            file_data = {\n                'filename': mp3_file,\n                'short_filename': self._create_short_filename(mp3_file),\n                'emotion_label': emotion_result['emotion'],\n                'emotion_confidence': emotion_result['confidence'],\n                **flat_features\n            }\n            \n            # Store sample for visualization\n            if self.sample_for_timeline is None:\n                self.sample_for_timeline = {\n                    'short_filename': file_data['short_filename'],\n                    'rms_frames': rms,\n                    'emotion': emotion_result['emotion']\n                }\n            \n            self.processed_data.append(file_data)\n            \n            # Cleanup\n            if os.path.exists(wav_path): os.remove(wav_path)\n            gc.collect()\n        \n        print(f\"Successfully processed {len(self.processed_data)} files\")\n    \n    def _flatten_features(self, features):\n        \"\"\"Flatten nested feature dictionary\"\"\"\n        flat_features = {}\n        for category, values in features.items():\n            if isinstance(values, dict):\n                for feature, value in values.items():\n                    if isinstance(value, np.ndarray):\n                        if len(value.shape) == 1:\n                            for i, v in enumerate(value):\n                                flat_features[f\"{category}_{feature}_{i}\"] = v\n                        else:\n                            flat_features[f\"{category}_{feature}\"] = np.mean(value)\n                    else:\n                        flat_features[f\"{category}_{feature}\"] = value\n            else:\n                flat_features[category] = values\n        return flat_features\n    \n    def create_features_dataframe(self):\n        \"\"\"Create enhanced features DataFrame\"\"\"\n        if not self.processed_data:\n            print(\"No processed data available!\"); return\n            \n        self.features_df = pd.DataFrame(self.processed_data)\n        \n        # Save features\n        features_path = os.path.join(self.output_folder, 'enhanced_audio_features.csv')\n        self.features_df.to_csv(features_path, index=False)\n        print(f\"Enhanced features DataFrame created with shape: {self.features_df.shape}\")\n        print(f\"Features saved to: {features_path}\")\n    \n    def perform_advanced_anomaly_detection(self):\n        \"\"\"Perform multi-level anomaly detection\"\"\"\n        if self.features_df is None:\n            print(\"Features DataFrame not created!\"); return\n            \n        # Select numerical features for anomaly detection\n        feature_columns = [col for col in self.features_df.columns \n                          if col not in ['filename', 'short_filename', 'emotion_label', 'emotion_confidence']\n                          and self.features_df[col].dtype in ['float64', 'int64']]\n        \n        X = self.features_df[feature_columns].fillna(0).values\n        \n        # Fit and detect anomalies\n        self.anomaly_detector.fit(X, feature_columns)\n        anomaly_results = self.anomaly_detector.detect_anomalies(X)\n        \n        # Add anomaly results to DataFrame\n        for anomaly_type, results in anomaly_results.items():\n            self.features_df[f'anomaly_{anomaly_type}'] = results\n        \n        # Main anomaly indicator\n        self.features_df['is_anomaly'] = anomaly_results['ensemble']\n        \n        print(f\"Anomaly detection completed:\")\n        for anomaly_type, results in anomaly_results.items():\n            count = np.sum(results)\n            print(f\"  - {anomaly_type}: {count} anomalies ({count/len(results)*100:.1f}%)\")\n    \n    def train_ml_prioritization(self):\n        \"\"\"Train machine learning models for call prioritization\"\"\"\n        if self.features_df is None:\n            print(\"Features DataFrame not created!\"); return\n            \n        # Select features for ML models\n        feature_columns = [col for col in self.features_df.columns \n                          if col not in ['filename', 'short_filename', 'emotion_label', 'emotion_confidence']\n                          and not col.startswith('anomaly_')\n                          and self.features_df[col].dtype in ['float64', 'int64']]\n        \n        # Train the ML prioritization system\n        self.ml_prioritizer.fit(self.features_df, feature_columns)\n        \n        # Make predictions\n        predictions = self.ml_prioritizer.predict(self.features_df, feature_columns)\n        \n        # Add predictions to DataFrame\n        self.features_df['priority_level'] = predictions['priority_classifier']\n        self.features_df['urgency_score'] = predictions['urgency_regressor']\n        self.features_df['risk_score'] = predictions['risk_scorer']\n        \n        # Calculate composite priority score\n        priority_weights = {'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}\n        self.features_df['priority_numeric'] = self.features_df['priority_level'].map(priority_weights)\n        self.features_df['composite_priority'] = (\n            self.features_df['priority_numeric'] * 0.4 +\n            self.features_df['urgency_score'] * 0.3 +\n            self.features_df['risk_score'] * 0.2 +\n            self.features_df['is_anomaly'] * 0.1\n        )\n        \n        print(\"ML prioritization training completed\")\n        print(f\"Priority distribution: {self.features_df['priority_level'].value_counts().to_dict()}\")\n    \n    def perform_clustering_analysis(self, n_clusters=4):\n        \"\"\"Enhanced clustering analysis with multiple algorithms\"\"\"\n        if self.features_df is None:\n            print(\"Features DataFrame not created!\"); return\n            \n        # Select features for clustering\n        feature_columns = [col for col in self.features_df.columns \n                          if col not in ['filename', 'short_filename', 'emotion_label', 'emotion_confidence', 'priority_level']\n                          and not col.startswith('anomaly_')\n                          and self.features_df[col].dtype in ['float64', 'int64']]\n        \n        X = self.features_df[feature_columns].fillna(0).values\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # K-Means clustering\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n        self.features_df['kmeans_cluster'] = kmeans.fit_predict(X_scaled)\n        \n        # DBSCAN clustering for density-based grouping\n        dbscan = DBSCAN(eps=0.5, min_samples=5)\n        self.features_df['dbscan_cluster'] = dbscan.fit_predict(X_scaled)\n        \n        # Dimensionality reduction for visualization\n        # PCA\n        pca = PCA(n_components=2, random_state=42)\n        pca_result = pca.fit_transform(X_scaled)\n        self.features_df['pca_x'] = pca_result[:, 0]\n        self.features_df['pca_y'] = pca_result[:, 1]\n        \n        # UMAP\n        umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n        umap_result = umap_reducer.fit_transform(X_scaled)\n        self.features_df['umap_x'] = umap_result[:, 0]\n        self.features_df['umap_y'] = umap_result[:, 1]\n        \n        # t-SNE\n        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X_scaled)-1))\n        tsne_result = tsne.fit_transform(X_scaled)\n        self.features_df['tsne_x'] = tsne_result[:, 0]\n        self.features_df['tsne_y'] = tsne_result[:, 1]\n        \n        print(f\"Clustering analysis completed with {n_clusters} K-means clusters\")\n        print(f\"DBSCAN found {len(set(self.features_df['dbscan_cluster'])) - (1 if -1 in self.features_df['dbscan_cluster'].values else 0)} clusters\")\n    \n    def create_comprehensive_visualizations(self):\n        \"\"\"Create comprehensive visualizations and insights\"\"\"\n        if self.features_df is None or self.features_df.empty:\n            print(\"No data to visualize\"); return\n            \n        # Set up the plotting style\n        plt.style.use('seaborn-v0_8')\n        fig_size = (15, 10)\n        \n        # 1. Enhanced Emotion Analysis\n        self._plot_emotion_analysis()\n        \n        # 2. Priority and Risk Analysis\n        self._plot_priority_analysis()\n        \n        # 3. Anomaly Analysis\n        self._plot_anomaly_analysis()\n        \n        # 4. Clustering Visualizations\n        self._plot_clustering_analysis()\n        \n        # 5. Feature Importance and Correlations\n        self._plot_feature_analysis()\n        \n        # 6. Advanced Timeline Analysis\n        self._plot_timeline_analysis()\n        \n        print(\"All visualizations created and saved\")\n    \n    def _plot_emotion_analysis(self):\n        \"\"\"Plot comprehensive emotion analysis\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # Emotion distribution\n        emotion_counts = self.features_df['emotion_label'].value_counts()\n        axes[0,0].pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%', \n                     colors=sns.color_palette(\"husl\", len(emotion_counts)))\n        axes[0,0].set_title('Emotion Distribution')\n        \n        # Emotion confidence distribution\n        sns.boxplot(data=self.features_df, x='emotion_label', y='emotion_confidence', ax=axes[0,1])\n        axes[0,1].set_title('Emotion Confidence by Type')\n        axes[0,1].tick_params(axis='x', rotation=45)\n        \n        # Emotion vs Duration\n        sns.scatterplot(data=self.features_df, x='general_duration', y='energy_rms', \n                       hue='emotion_label', alpha=0.7, ax=axes[1,0])\n        axes[1,0].set_title('Emotion Distribution: Duration vs Energy')\n        \n        # Emotion correlation with audio features\n        emotion_features = ['energy_rms', 'pitch_mean', 'silence_ratio', 'rhythm_speaking_rate']\n        emotion_data = self.features_df.groupby('emotion_label')[emotion_features].mean()\n        sns.heatmap(emotion_data.T, annot=True, cmap='RdYlBu_r', ax=axes[1,1])\n        axes[1,1].set_title('Average Features by Emotion')\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(self.output_folder, 'emotion_analysis.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def _plot_priority_analysis(self):\n        \"\"\"Plot priority and risk analysis\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # Priority level distribution\n        priority_counts = self.features_df['priority_level'].value_counts()\n        colors = ['red', 'orange', 'green']\n        axes[0,0].bar(priority_counts.index, priority_counts.values, color=colors[:len(priority_counts)])\n        axes[0,0].set_title('Call Priority Distribution')\n        axes[0,0].set_ylabel('Number of Calls')\n        \n        # Composite priority vs emotion\n        sns.boxplot(data=self.features_df, x='emotion_label', y='composite_priority', ax=axes[0,1])\n        axes[0,1].set_title('Priority Score by Emotion')\n        axes[0,1].tick_params(axis='x', rotation=45)\n        \n        # Risk score distribution\n        axes[1,0].hist(self.features_df['risk_score'], bins=2, alpha=0.7, color='red', edgecolor='black')\n        axes[1,0].set_title('Risk Score Distribution')\n        axes[1,0].set_xlabel('Risk Score (0=Low, 1=High)')\n        axes[1,0].set_ylabel('Number of Calls')\n        \n        # Priority vs Anomaly\n        priority_anomaly = pd.crosstab(self.features_df['priority_level'], self.features_df['is_anomaly'])\n        sns.heatmap(priority_anomaly, annot=True, fmt='d', cmap='Reds', ax=axes[1,1])\n        axes[1,1].set_title('Priority Level vs Anomaly Detection')\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(self.output_folder, 'priority_analysis.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def _plot_anomaly_analysis(self):\n        \"\"\"Plot comprehensive anomaly analysis\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # Anomaly detection comparison\n        anomaly_types = ['isolation_forest', 'statistical', 'percentile', 'ensemble']\n        anomaly_counts = [self.features_df[f'anomaly_{atype}'].sum() for atype in anomaly_types]\n        \n        axes[0,0].bar(anomaly_types, anomaly_counts, color=['blue', 'green', 'orange', 'red'])\n        axes[0,0].set_title('Anomaly Detection Method Comparison')\n        axes[0,0].set_ylabel('Number of Anomalies')\n        axes[0,0].tick_params(axis='x', rotation=45)\n        \n        # Anomalies in feature space\n        sns.scatterplot(data=self.features_df, x='energy_rms', y='pitch_mean', \n                       hue='is_anomaly', palette={0: 'blue', 1: 'red'}, alpha=0.7, ax=axes[0,1])\n        axes[0,1].set_title('Anomalies in Energy-Pitch Space')\n        \n        # Anomaly vs Emotion\n        anomaly_emotion = pd.crosstab(self.features_df['emotion_label'], self.features_df['is_anomaly'])\n        sns.heatmap(anomaly_emotion, annot=True, fmt='d', cmap='Blues', ax=axes[1,0])\n        axes[1,0].set_title('Anomalies by Emotion Type')\n        \n        # Duration vs Silence for anomalies\n        sns.scatterplot(data=self.features_df, x='general_duration', y='silence_ratio', \n                       hue='is_anomaly', palette={0: 'lightblue', 1: 'red'}, alpha=0.7, ax=axes[1,1])\n        axes[1,1].set_title('Anomalies: Duration vs Silence Ratio')\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(self.output_folder, 'anomaly_analysis.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def _plot_clustering_analysis(self):\n        \"\"\"Plot clustering analysis results\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # UMAP clustering\n        sns.scatterplot(data=self.features_df, x='umap_x', y='umap_y', \n                       hue='kmeans_cluster', palette='viridis', alpha=0.7, ax=axes[0,0])\n        axes[0,0].set_title('UMAP Projection with K-Means Clusters')\n        \n        # PCA clustering\n        sns.scatterplot(data=self.features_df, x='pca_x', y='pca_y', \n                       hue='kmeans_cluster', palette='viridis', alpha=0.7, ax=axes[0,1])\n        axes[0,1].set_title('PCA Projection with K-Means Clusters')\n        \n        # t-SNE clustering\n        sns.scatterplot(data=self.features_df, x='tsne_x', y='tsne_y', \n                       hue='kmeans_cluster', palette='viridis', alpha=0.7, ax=axes[1,0])\n        axes[1,0].set_title('t-SNE Projection with K-Means Clusters')\n        \n        # Cluster characteristics\n        cluster_features = ['energy_rms', 'pitch_mean', 'silence_ratio', 'rhythm_speaking_rate']\n        cluster_data = self.features_df.groupby('kmeans_cluster')[cluster_features].mean()\n        sns.heatmap(cluster_data.T, annot=True, cmap='RdYlBu_r', ax=axes[1,1])\n        axes[1,1].set_title('Average Features by Cluster')\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(self.output_folder, 'clustering_analysis.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def _plot_feature_analysis(self):\n        \"\"\"Plot feature importance and correlations\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # Feature correlation matrix\n        feature_columns = ['energy_rms', 'pitch_mean', 'pitch_std', 'silence_ratio', \n                          'rhythm_speaking_rate', 'spectral_centroid', 'voice_quality_jitter']\n        if all(col in self.features_df.columns for col in feature_columns):\n            corr_matrix = self.features_df[feature_columns].corr()\n            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0,0])\n            axes[0,0].set_title('Feature Correlation Matrix')\n        \n        # Feature distributions by emotion\n        key_features = ['energy_rms', 'pitch_mean', 'silence_ratio']\n        for i, feature in enumerate(key_features):\n            if i < 3:  # We have 3 remaining subplots\n                row, col = divmod(i+1, 2)\n                if row == 0: col = 1\n                elif row == 1: col = i-1\n                \n                sns.boxplot(data=self.features_df, x='emotion_label', y=feature, ax=axes[row, col])\n                axes[row, col].set_title(f'{feature} by Emotion')\n                axes[row, col].tick_params(axis='x', rotation=45)\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(self.output_folder, 'feature_analysis.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def _plot_timeline_analysis(self):\n        \"\"\"Plot sample timeline analysis\"\"\"\n        if self.sample_for_timeline:\n            fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n            \n            sample = self.sample_for_timeline\n            time_frames = np.arange(len(sample['rms_frames'])) * 0.01\n            \n            # Energy timeline\n            axes[0].plot(time_frames, sample['rms_frames'], alpha=0.8, linewidth=1.5, color='blue')\n            axes[0].set_title(f\"Sample Audio Timeline: {sample['short_filename']} (Emotion: {sample['emotion']})\")\n            axes[0].set_ylabel('Energy (RMS)')\n            axes[0].grid(True, alpha=0.3)\n            \n            # Smoothed energy with peaks\n            smooth_rms = savgol_filter(sample['rms_frames'], \n                                     window_length=min(21, len(sample['rms_frames'])//2*2+1), \n                                     polyorder=2)\n            peaks, _ = find_peaks(smooth_rms, height=np.percentile(smooth_rms, 70))\n            \n            axes[1].plot(time_frames, smooth_rms, color='green', linewidth=2, label='Smoothed Energy')\n            axes[1].scatter(time_frames[peaks], smooth_rms[peaks], color='red', s=50, \n                          label=f'Peaks ({len(peaks)})', zorder=5)\n            axes[1].set_xlabel('Time (seconds)')\n            axes[1].set_ylabel('Smoothed Energy')\n            axes[1].legend()\n            axes[1].grid(True, alpha=0.3)\n            \n            plt.tight_layout()\n            plt.savefig(os.path.join(self.output_folder, 'timeline_analysis.png'), dpi=300, bbox_inches='tight')\n            plt.close()\n    \n    def generate_comprehensive_report(self):\n        \"\"\"Generate comprehensive analysis report\"\"\"\n        if self.features_df is None or self.features_df.empty:\n            print(\"No data available for report generation\")\n            return\n            \n        report_path = os.path.join(self.output_folder, 'comprehensive_analysis_report.txt')\n        \n        with open(report_path, 'w') as f:\n            f.write(\"=\"*80 + \"\\n\")\n            f.write(\"COMPREHENSIVE CALL CENTER AUDIO ANALYSIS REPORT\\n\")\n            f.write(\"=\"*80 + \"\\n\\n\")\n            \n            # Summary statistics\n            f.write(\"SUMMARY STATISTICS\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            f.write(f\"Total calls analyzed: {len(self.features_df)}\\n\")\n            f.write(f\"Average call duration: {self.features_df['general_duration'].mean():.2f} seconds\\n\")\n            f.write(f\"Duration range: {self.features_df['general_duration'].min():.1f} - {self.features_df['general_duration'].max():.1f} seconds\\n\\n\")\n            \n            # Emotion analysis\n            f.write(\"EMOTION ANALYSIS\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            emotion_stats = self.features_df['emotion_label'].value_counts()\n            for emotion, count in emotion_stats.items():\n                percentage = (count / len(self.features_df)) * 100\n                f.write(f\"{emotion.capitalize()}: {count} calls ({percentage:.1f}%)\\n\")\n            \n            avg_confidence = self.features_df['emotion_confidence'].mean()\n            f.write(f\"\\nAverage emotion confidence: {avg_confidence:.3f}\\n\\n\")\n            \n            # Priority analysis\n            f.write(\"PRIORITY ANALYSIS\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            priority_stats = self.features_df['priority_level'].value_counts()\n            for priority, count in priority_stats.items():\n                percentage = (count / len(self.features_df)) * 100\n                f.write(f\"{priority} priority: {count} calls ({percentage:.1f}%)\\n\")\n            \n            high_priority_calls = self.features_df[self.features_df['priority_level'] == 'HIGH']\n            f.write(f\"\\nHigh priority calls breakdown:\\n\")\n            if not high_priority_calls.empty:\n                high_priority_emotions = high_priority_calls['emotion_label'].value_counts()\n                for emotion, count in high_priority_emotions.items():\n                    f.write(f\"  - {emotion}: {count} calls\\n\")\n            \n            # Anomaly analysis\n            f.write(f\"\\nANOMALY ANALYSIS\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            total_anomalies = self.features_df['is_anomaly'].sum()\n            anomaly_percentage = (total_anomalies / len(self.features_df)) * 100\n            f.write(f\"Total anomalies detected: {total_anomalies} ({anomaly_percentage:.1f}%)\\n\")\n            \n            # Top priority calls for review\n            f.write(f\"\\nTOP PRIORITY CALLS FOR MANUAL REVIEW\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            top_priority = self.features_df.nlargest(10, 'composite_priority')\n            \n            for idx, (_, call) in enumerate(top_priority.iterrows(), 1):\n                f.write(f\"{idx}. {call['filename']}\\n\")\n                f.write(f\"   Priority: {call['priority_level']}, Emotion: {call['emotion_label']}\\n\")\n                f.write(f\"   Duration: {call['general_duration']:.1f}s, Composite Score: {call['composite_priority']:.2f}\\n\")\n                f.write(f\"   Anomaly: {'Yes' if call['is_anomaly'] else 'No'}\\n\\n\")\n            \n            # Recommendations\n            f.write(\"RECOMMENDATIONS\\n\")\n            f.write(\"-\" * 40 + \"\\n\")\n            \n            # Identify patterns\n            angry_calls = len(self.features_df[self.features_df['emotion_label'] == 'angry'])\n            frustrated_calls = len(self.features_df[self.features_df['emotion_label'] == 'frustrated'])\n            confused_calls = len(self.features_df[self.features_df['emotion_label'] == 'confused'])\n            \n            if angry_calls > len(self.features_df) * 0.15:\n                f.write(\"⚠️  High percentage of angry calls detected - consider agent training on de-escalation\\n\")\n            \n            if frustrated_calls > len(self.features_df) * 0.2:\n                f.write(\"⚠️  High frustration levels - review common issues and improve FAQ/knowledge base\\n\")\n            \n            if confused_calls > len(self.features_df) * 0.25:\n                f.write(\"⚠️  Many confused customers - consider improving call routing and agent preparation\\n\")\n            \n            long_calls = len(self.features_df[self.features_df['general_duration'] > \n                                           self.features_df['general_duration'].quantile(0.9)])\n            if long_calls > 0:\n                f.write(f\"📈 {long_calls} exceptionally long calls detected - investigate for efficiency improvements\\n\")\n            \n            f.write(f\"\\n✅ Prioritize manual review of {len(top_priority)} highest-scoring calls\\n\")\n            f.write(f\"✅ Focus quality assurance on {total_anomalies} anomalous calls\\n\")\n            f.write(f\"✅ Consider additional agent training based on emotion distribution patterns\\n\")\n        \n        print(f\"Comprehensive report generated: {report_path}\")\n    \n    def save_results(self):\n        \"\"\"Save all results to files\"\"\"\n        if self.features_df is None:\n            print(\"No results to save\")\n            return\n            \n        # Save main results\n        results_path = os.path.join(self.output_folder, 'final_analysis_results.csv')\n        self.features_df.to_csv(results_path, index=False)\n        \n        # Save priority calls for immediate action\n        high_priority = self.features_df[\n            (self.features_df['priority_level'] == 'HIGH') | \n            (self.features_df['is_anomaly'] == 1)\n        ].sort_values('composite_priority', ascending=False)\n        \n        priority_path = os.path.join(self.output_folder, 'priority_calls_for_review.csv')\n        high_priority[['filename', 'emotion_label', 'priority_level', 'composite_priority', \n                      'is_anomaly', 'general_duration']].to_csv(priority_path, index=False)\n        \n        # Save model for future use\n        model_path = os.path.join(self.output_folder, 'ml_prioritizer.pkl')\n        joblib.dump(self.ml_prioritizer, model_path)\n        \n        print(f\"Results saved:\")\n        print(f\"  - Full analysis: {results_path}\")\n        print(f\"  - Priority calls: {priority_path}\")\n        print(f\"  - ML model: {model_path}\")\n\n# Main execution function\ndef main():\n    \"\"\"Main execution function with comprehensive analysis\"\"\"\n    AUDIO_FOLDER = \"/kaggle/input/asdfggh/Audio file\"\n    N_CLUSTERS = 4\n    \n    print(\"Starting Enhanced Audio Analysis Pipeline...\")\n    print(\"=\"*60)\n    \n    # Initialize analyzer\n    analyzer = EnhancedAudioAnalyzer(AUDIO_FOLDER)\n    \n    # Process all files\n    analyzer.process_all_files()\n    if not analyzer.processed_data:\n        print(\"No files were processed successfully!\")\n        return None\n    \n    # Create features DataFrame\n    analyzer.create_features_dataframe()\n    \n    # Perform advanced anomaly detection\n    analyzer.perform_advanced_anomaly_detection()\n    \n    # Train ML prioritization models\n    analyzer.train_ml_prioritization()\n    \n    # Perform clustering analysis\n    analyzer.perform_clustering_analysis(n_clusters=N_CLUSTERS)\n    \n    # Create comprehensive visualizations\n    analyzer.create_comprehensive_visualizations()\n    \n    # Generate comprehensive report\n    analyzer.generate_comprehensive_report()\n    \n    # Save all results\n    analyzer.save_results()\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ENHANCED AUDIO ANALYSIS COMPLETE!\")\n    print(f\"All outputs saved to: {analyzer.output_folder}\")\n    print(\"=\"*60)\n    \n    return analyzer\n\n# Run the enhanced analysis\nif __name__ == \"__main__\":\n    try:\n        analyzer = main()\n        if analyzer:\n            print(\"\\nAnalysis pipeline completed successfully!\")\n            print(f\"Processed {len(analyzer.processed_data)} audio files\")\n            print(\"Check the output folder for detailed results and visualizations\")\n    except Exception as e:\n        print(f\"\\nAn error occurred during execution: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T09:22:41.626919Z","iopub.execute_input":"2025-06-20T09:22:41.627264Z","iopub.status.idle":"2025-06-20T09:31:09.642721Z","shell.execute_reply.started":"2025-06-20T09:22:41.627222Z","shell.execute_reply":"2025-06-20T09:31:09.641924Z"}},"outputs":[{"name":"stderr","text":"2025-06-20 09:22:58.892832: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750411379.062884      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750411379.114008      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Starting Enhanced Audio Analysis Pipeline...\n============================================================\nAdvanced Emotion Classifier initialized with 8 emotion categories\nProcessing 10 MP3 files with enhanced analysis...\n","output_type":"stream"},{"name":"stderr","text":"Processing files: 100%|██████████| 10/10 [07:34<00:00, 45.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Successfully processed 10 files\nEnhanced features DataFrame created with shape: (10, 53)\nFeatures saved to: /kaggle/working/enhanced_audio_analysis/enhanced_audio_features.csv\nAnomaly detection completed:\n  - ensemble: 1 anomalies (10.0%)\n  - isolation_forest: 2 anomalies (20.0%)\n  - statistical: 0 anomalies (0.0%)\n  - percentile: 2 anomalies (20.0%)\n\nModel Performance Evaluation:\n----------------------------------------\nPriority Classifier Accuracy: 0.694 (+/- 0.079)\nUrgency Regressor Accuracy: 0.694 (+/- 0.550)\nRisk Scorer AUC: nan (+/- nan)\nML prioritization training completed\nPriority distribution: {'MEDIUM': 6, 'LOW': 2, 'HIGH': 2}\nClustering analysis completed with 4 K-means clusters\nDBSCAN found 0 clusters\nAll visualizations created and saved\nComprehensive report generated: /kaggle/working/enhanced_audio_analysis/comprehensive_analysis_report.txt\nResults saved:\n  - Full analysis: /kaggle/working/enhanced_audio_analysis/final_analysis_results.csv\n  - Priority calls: /kaggle/working/enhanced_audio_analysis/priority_calls_for_review.csv\n  - ML model: /kaggle/working/enhanced_audio_analysis/ml_prioritizer.pkl\n\n============================================================\nENHANCED AUDIO ANALYSIS COMPLETE!\nAll outputs saved to: /kaggle/working/enhanced_audio_analysis\n============================================================\n\nAnalysis pipeline completed successfully!\nProcessed 10 audio files\nCheck the output folder for detailed results and visualizations\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}